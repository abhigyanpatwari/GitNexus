# Worker Pool Implementation Guide

## ðŸŽ¯ Overview

The Worker Pool implementation provides **massive performance improvements** for large codebases by parallelizing CPU-intensive operations like Tree-sitter parsing, AST analysis, and code processing.

## ðŸš€ Performance Benefits

### **Expected Speedup:**
- **Small codebases (< 100 files)**: 1.5-2x speedup
- **Medium codebases (100-1000 files)**: 2-4x speedup  
- **Large codebases (1000+ files)**: 4-8x speedup

### **Key Improvements:**
- **Parallel file parsing** - Multiple files processed simultaneously
- **Concurrent Tree-sitter operations** - AST generation in parallel
- **Better CPU utilization** - Leverages all available cores
- **Improved UI responsiveness** - Main thread freed up

---

## ðŸ“ File Structure

```
src/
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ web-worker-pool.ts          # Main worker pool implementation
â”‚   â””â”€â”€ worker-pool-test.ts         # Test suite
â”œâ”€â”€ core/ingestion/
â”‚   â”œâ”€â”€ parallel-parsing-processor.ts  # Parallel parsing with workers
â”‚   â””â”€â”€ parallel-pipeline.ts           # Parallel pipeline integration
â””â”€â”€ config/
    â””â”€â”€ feature-flags.ts            # Worker pool feature flags

public/workers/
â”œâ”€â”€ tree-sitter-worker.js           # Tree-sitter parsing worker
â”œâ”€â”€ generic-worker.js               # Generic processing worker
â””â”€â”€ file-processing-worker.js       # File analysis worker
```

---

## ðŸ”§ Core Components

### **1. WebWorkerPool Class**
```typescript
import { WebWorkerPool } from './src/lib/web-worker-pool.js';

const workerPool = new WebWorkerPool({
  maxWorkers: navigator.hardwareConcurrency,
  workerScript: '/workers/tree-sitter-worker.js',
  timeout: 30000,
  name: 'MyWorkerPool'
});
```

**Key Features:**
- **Automatic worker management** - Creates, recycles, and terminates workers
- **Task queuing** - Handles task distribution and load balancing
- **Error recovery** - Graceful handling of worker failures
- **Progress tracking** - Real-time progress callbacks
- **Statistics** - Detailed performance metrics

### **2. ParallelParsingProcessor**
```typescript
import { ParallelParsingProcessor } from './src/core/ingestion/parallel-parsing-processor.ts';

const processor = new ParallelParsingProcessor();
await processor.process(graph, {
  filePaths: ['file1.ts', 'file2.ts'],
  fileContents: fileContentsMap,
  options: { useParallelProcessing: true }
});
```

**Key Features:**
- **Parallel file parsing** - Processes multiple files simultaneously
- **Worker pool integration** - Uses WebWorkerPool for CPU-intensive tasks
- **Memory optimization** - Efficient result aggregation
- **Error handling** - Continues processing even if some files fail

### **3. ParallelGraphPipeline**
```typescript
import { ParallelGraphPipeline } from './src/core/ingestion/parallel-pipeline.ts';

const pipeline = new ParallelGraphPipeline();
pipeline.setProgressCallback((progress) => {
  console.log(`${progress.phase}: ${progress.progress}%`);
});

const graph = await pipeline.run({
  projectRoot: '/path/to/project',
  projectName: 'MyProject',
  filePaths: allFilePaths,
  fileContents: fileContentsMap,
  options: { useParallelProcessing: true }
});
```

---

## ðŸŽ® Usage Examples

### **Basic Worker Pool Usage**
```typescript
import { WebWorkerPool } from './src/lib/web-worker-pool.js';

// Create worker pool
const workerPool = new WebWorkerPool({
  maxWorkers: 4,
  workerScript: '/workers/generic-worker.js'
});

// Execute single task
const result = await workerPool.execute({
  taskType: 'textAnalysis',
  text: 'Hello world!',
  analysisType: 'wordCount'
});

// Execute multiple tasks in parallel
const results = await workerPool.executeAll([
  { taskType: 'textAnalysis', text: 'Task 1', analysisType: 'wordCount' },
  { taskType: 'textAnalysis', text: 'Task 2', analysisType: 'wordCount' }
]);

// Execute with progress tracking
const results = await workerPool.executeWithProgress(
  tasks,
  (completed, total) => {
    console.log(`Progress: ${(completed/total)*100}%`);
  }
);

// Cleanup
await workerPool.shutdown();
```

### **File Processing with Workers**
```typescript
import { WebWorkerPoolUtils } from './src/lib/web-worker-pool.js';

// Create specialized file processing pool
const filePool = WebWorkerPoolUtils.createCPUPool({
  workerScript: '/workers/file-processing-worker.js'
});

// Analyze file structure
const analysis = await filePool.execute({
  processorType: 'analyzeStructure',
  filePath: '/src/main.ts',
  content: fileContent
});

// Extract dependencies
const dependencies = await filePool.execute({
  processorType: 'extractDependencies',
  filePath: '/src/main.ts',
  content: fileContent
});
```

### **Parallel Pipeline Integration**
```typescript
import { ParallelGraphPipeline } from './src/core/ingestion/parallel-pipeline.ts';

// Check if parallel processing is supported
if (ParallelGraphPipeline.isParallelProcessingSupported()) {
  const pipeline = new ParallelGraphPipeline();
  
  // Set up progress tracking
  pipeline.setProgressCallback((progress) => {
    console.log(`${progress.phase}: ${progress.message} (${progress.progress}%)`);
  });
  
  // Run parallel processing
  const graph = await pipeline.run({
    projectRoot: '/path/to/project',
    projectName: 'MyProject',
    filePaths: allFilePaths,
    fileContents: fileContentsMap,
    options: {
      useParallelProcessing: true,
      maxWorkers: ParallelGraphPipeline.getOptimalWorkerCount()
    }
  });
  
  // Get worker pool statistics
  const stats = pipeline.getWorkerPoolStats();
  console.log('Worker pool stats:', stats);
}
```

---

## âš™ï¸ Configuration

### **Feature Flags**
```typescript
import { featureFlags } from './src/config/feature-flags.js';

// Enable worker pool features
featureFlags.enableWorkerPool();

// Or configure individually
featureFlags.setFlags({
  enableWorkerPool: true,
  enableParallelParsing: true,
  enableParallelProcessing: true
});

// Check if enabled
if (featureFlags.getFlag('enableWorkerPool')) {
  // Use worker pool
}
```

### **Worker Pool Options**
```typescript
const workerPoolOptions = {
  maxWorkers: navigator.hardwareConcurrency, // Number of workers
  workerScript: '/workers/tree-sitter-worker.js', // Worker script path
  timeout: 30000, // Task timeout in milliseconds
  name: 'MyWorkerPool' // Pool name for logging
};
```

### **Optimal Worker Counts**
```typescript
import { WebWorkerPoolUtils } from './src/lib/web-worker-pool.js';

// Get optimal worker count for different task types
const cpuWorkers = WebWorkerPoolUtils.getOptimalWorkerCount('cpu');
const ioWorkers = WebWorkerPoolUtils.getOptimalWorkerCount('io');
const mixedWorkers = WebWorkerPoolUtils.getOptimalWorkerCount('mixed');

// Get hardware concurrency
const concurrency = WebWorkerPoolUtils.getHardwareConcurrency();
```

---

## ðŸ§ª Testing

### **Run Test Suite**
```typescript
import { runWorkerPoolTests } from './src/lib/worker-pool-test.js';

// Run all tests
await runWorkerPoolTests();
```

### **Individual Tests**
```typescript
import { 
  testWorkerPoolBasic,
  testFileProcessingPool,
  testWorkerPoolPerformance,
  testWorkerPoolErrorHandling
} from './src/lib/worker-pool-test.js';

// Test basic functionality
await testWorkerPoolBasic();

// Test file processing
await testFileProcessingPool();

// Test performance
await testWorkerPoolPerformance();

// Test error handling
await testWorkerPoolErrorHandling();
```

### **Browser Console Testing**
```javascript
// Available globally in browser
await window.runWorkerPoolTests();
await window.testWorkerPoolBasic();
await window.testWorkerPoolPerformance();
```

---

## ðŸ“Š Performance Monitoring

### **Worker Pool Statistics**
```typescript
const stats = workerPool.getStats();
console.log({
  totalWorkers: stats.totalWorkers,
  availableWorkers: stats.availableWorkers,
  activeTasks: stats.activeTasks,
  queuedTasks: stats.queuedTasks,
  maxWorkers: stats.maxWorkers,
  memoryUsage: stats.memoryUsage
});
```

### **Performance Metrics**
```typescript
// Track processing time
const startTime = performance.now();
const results = await workerPool.executeAll(tasks);
const endTime = performance.now();

console.log({
  totalTime: endTime - startTime,
  averageTimePerTask: (endTime - startTime) / tasks.length,
  processingRate: tasks.length / ((endTime - startTime) / 1000)
});
```

---

## ðŸš¨ Error Handling

### **Worker Errors**
```typescript
workerPool.on('workerError', (data) => {
  console.warn(`Worker ${data.workerId} error:`, data.error);
});

workerPool.on('workerCreated', (data) => {
  console.log(`Worker ${data.workerId} created`);
});

workerPool.on('shutdown', () => {
  console.log('Worker pool shutdown');
});
```

### **Task Timeouts**
```typescript
try {
  const result = await workerPool.execute(task);
} catch (error) {
  if (error.message.includes('timed out')) {
    console.warn('Task timed out, retrying...');
    // Implement retry logic
  }
}
```

### **Fallback to Sequential Processing**
```typescript
if (ParallelGraphPipeline.isParallelProcessingSupported()) {
  // Use parallel processing
  const pipeline = new ParallelGraphPipeline();
} else {
  // Fallback to sequential processing
  const pipeline = new GraphPipeline();
}
```

---

## ðŸ”„ Migration Guide

### **From Sequential to Parallel Processing**

**Before (Sequential):**
```typescript
import { GraphPipeline } from './src/core/ingestion/pipeline.ts';

const pipeline = new GraphPipeline();
const graph = await pipeline.run(input);
```

**After (Parallel):**
```typescript
import { ParallelGraphPipeline } from './src/core/ingestion/parallel-pipeline.ts';

const pipeline = new ParallelGraphPipeline();
pipeline.setProgressCallback((progress) => {
  console.log(`${progress.phase}: ${progress.progress}%`);
});

const graph = await pipeline.run({
  ...input,
  options: { useParallelProcessing: true }
});
```

### **From BatchProcessor to WorkerPool**

**Before (Sequential batches):**
```typescript
const batchProcessor = new BatchProcessor(10, async (files) => {
  for (const file of files) {
    await processFile(file); // Sequential within batch
  }
});
```

**After (Parallel workers):**
```typescript
const workerPool = new WebWorkerPool({
  maxWorkers: 4,
  workerScript: '/workers/tree-sitter-worker.js'
});

const results = await workerPool.executeAll(
  files.map(file => ({ filePath: file, content: fileContents.get(file) }))
);
```

---

## ðŸŽ¯ Best Practices

### **1. Worker Pool Configuration**
- **CPU-intensive tasks**: Use `navigator.hardwareConcurrency` workers
- **I/O-intensive tasks**: Use 2-4x more workers than CPU cores
- **Mixed tasks**: Use 2-8 workers depending on workload

### **2. Task Design**
- **Keep tasks independent** - Avoid shared state between workers
- **Serialize data efficiently** - Minimize data transfer overhead
- **Handle errors gracefully** - Implement proper error recovery

### **3. Memory Management**
- **Monitor memory usage** - Use `performance.memory` API
- **Clean up resources** - Always call `workerPool.shutdown()`
- **Batch large datasets** - Process in chunks to avoid memory issues

### **4. Performance Optimization**
- **Profile worker performance** - Monitor task execution times
- **Adjust worker count** - Find optimal balance for your workload
- **Use appropriate timeouts** - Set realistic timeout values

---

## ðŸš€ Ready to Use!

The Worker Pool implementation is **fully functional** and ready for production use. It provides:

âœ… **Massive performance improvements** for large codebases  
âœ… **Automatic worker management** and error recovery  
âœ… **Progress tracking** and performance monitoring  
âœ… **Easy integration** with existing pipeline  
âœ… **Comprehensive testing** and documentation  

**Next Steps:**
1. Test with your codebase to measure performance gains
2. Adjust worker counts based on your system capabilities
3. Monitor memory usage and optimize as needed
4. Enjoy faster, more responsive code analysis! ðŸŽ‰
